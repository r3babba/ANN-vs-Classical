{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Assignment IV– Individual Take Home Assignment</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>1. ANN regression model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "#Import Variables & standardize\n",
    "dataset=np.loadtxt(\"data/school_grades.csv\", delimiter=\",\", skiprows=1)\n",
    "x=dataset[:,0:4]\n",
    "y=dataset[:,4]\n",
    "y=np.reshape(y, (-1,1))\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "print(scaler_x.fit(x))\n",
    "xscale=scaler_x.transform(x)\n",
    "print(scaler_y.fit(y))\n",
    "yscale=scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train & test\n",
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 12)                60        \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 173\n",
      "Trainable params: 173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#defining a 3 layer deep NN [12,8,1]\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The mean_squared_error (mse) and mean_absolute_error (mae) are our loss functions – i.e. an estimate of how accurate the neural network is in predicting the test data. \n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 236 samples, validate on 60 samples\n",
      "Epoch 1/150\n",
      "236/236 [==============================] - 0s 826us/sample - loss: 0.2928 - mse: 0.2928 - mae: 0.4997 - val_loss: 0.2654 - val_mse: 0.2654 - val_mae: 0.4541\n",
      "Epoch 2/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.2488 - mse: 0.2488 - mae: 0.4617 - val_loss: 0.2205 - val_mse: 0.2205 - val_mae: 0.4156\n",
      "Epoch 3/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.2016 - mse: 0.2016 - mae: 0.4157 - val_loss: 0.1757 - val_mse: 0.1757 - val_mae: 0.3716\n",
      "Epoch 4/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.1558 - mse: 0.1558 - mae: 0.3654 - val_loss: 0.1340 - val_mse: 0.1340 - val_mae: 0.3234\n",
      "Epoch 5/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.1148 - mse: 0.1148 - mae: 0.3116 - val_loss: 0.0996 - val_mse: 0.0996 - val_mae: 0.2757\n",
      "Epoch 6/150\n",
      "236/236 [==============================] - 0s 55us/sample - loss: 0.0813 - mse: 0.0813 - mae: 0.2569 - val_loss: 0.0736 - val_mse: 0.0736 - val_mae: 0.2322\n",
      "Epoch 7/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0568 - mse: 0.0568 - mae: 0.2085 - val_loss: 0.0566 - val_mse: 0.0566 - val_mae: 0.1965\n",
      "Epoch 8/150\n",
      "236/236 [==============================] - 0s 55us/sample - loss: 0.0407 - mse: 0.0407 - mae: 0.1672 - val_loss: 0.0473 - val_mse: 0.0473 - val_mae: 0.1728\n",
      "Epoch 9/150\n",
      "236/236 [==============================] - 0s 59us/sample - loss: 0.0310 - mse: 0.0310 - mae: 0.1372 - val_loss: 0.0434 - val_mse: 0.0434 - val_mae: 0.1562\n",
      "Epoch 10/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0273 - mse: 0.0273 - mae: 0.1233 - val_loss: 0.0422 - val_mse: 0.0422 - val_mae: 0.1492\n",
      "Epoch 11/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0255 - mse: 0.0255 - mae: 0.1148 - val_loss: 0.0415 - val_mse: 0.0415 - val_mae: 0.1458\n",
      "Epoch 12/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0246 - mse: 0.0246 - mae: 0.1109 - val_loss: 0.0406 - val_mse: 0.0406 - val_mae: 0.1430\n",
      "Epoch 13/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0237 - mse: 0.0237 - mae: 0.1078 - val_loss: 0.0390 - val_mse: 0.0390 - val_mae: 0.1393\n",
      "Epoch 14/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0225 - mse: 0.0225 - mae: 0.1051 - val_loss: 0.0373 - val_mse: 0.0373 - val_mae: 0.1360\n",
      "Epoch 15/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0215 - mse: 0.0215 - mae: 0.1032 - val_loss: 0.0357 - val_mse: 0.0357 - val_mae: 0.1330\n",
      "Epoch 16/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0206 - mse: 0.0206 - mae: 0.1012 - val_loss: 0.0343 - val_mse: 0.0343 - val_mae: 0.1304\n",
      "Epoch 17/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0196 - mse: 0.0196 - mae: 0.0986 - val_loss: 0.0331 - val_mse: 0.0331 - val_mae: 0.1274\n",
      "Epoch 18/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0187 - mse: 0.0187 - mae: 0.0955 - val_loss: 0.0321 - val_mse: 0.0321 - val_mae: 0.1242\n",
      "Epoch 19/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0177 - mse: 0.0177 - mae: 0.0922 - val_loss: 0.0311 - val_mse: 0.0311 - val_mae: 0.1211\n",
      "Epoch 20/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0168 - mse: 0.0168 - mae: 0.0890 - val_loss: 0.0302 - val_mse: 0.0302 - val_mae: 0.1181\n",
      "Epoch 21/150\n",
      "236/236 [==============================] - 0s 59us/sample - loss: 0.0159 - mse: 0.0159 - mae: 0.0860 - val_loss: 0.0290 - val_mse: 0.0290 - val_mae: 0.1148\n",
      "Epoch 22/150\n",
      "236/236 [==============================] - 0s 64us/sample - loss: 0.0151 - mse: 0.0151 - mae: 0.0835 - val_loss: 0.0276 - val_mse: 0.0276 - val_mae: 0.1117\n",
      "Epoch 23/150\n",
      "236/236 [==============================] - 0s 85us/sample - loss: 0.0141 - mse: 0.0141 - mae: 0.0803 - val_loss: 0.0265 - val_mse: 0.0265 - val_mae: 0.1086\n",
      "Epoch 24/150\n",
      "236/236 [==============================] - 0s 64us/sample - loss: 0.0133 - mse: 0.0133 - mae: 0.0781 - val_loss: 0.0254 - val_mse: 0.0254 - val_mae: 0.1060\n",
      "Epoch 25/150\n",
      "236/236 [==============================] - 0s 64us/sample - loss: 0.0126 - mse: 0.0126 - mae: 0.0757 - val_loss: 0.0245 - val_mse: 0.0245 - val_mae: 0.1030\n",
      "Epoch 26/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0120 - mse: 0.0120 - mae: 0.0737 - val_loss: 0.0238 - val_mse: 0.0238 - val_mae: 0.0997\n",
      "Epoch 27/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0114 - mse: 0.0114 - mae: 0.0719 - val_loss: 0.0229 - val_mse: 0.0229 - val_mae: 0.0969\n",
      "Epoch 28/150\n",
      "236/236 [==============================] - 0s 59us/sample - loss: 0.0109 - mse: 0.0109 - mae: 0.0705 - val_loss: 0.0221 - val_mse: 0.0221 - val_mae: 0.0943\n",
      "Epoch 29/150\n",
      "236/236 [==============================] - 0s 55us/sample - loss: 0.0105 - mse: 0.0105 - mae: 0.0695 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.0920\n",
      "Epoch 30/150\n",
      "236/236 [==============================] - 0s 55us/sample - loss: 0.0101 - mse: 0.0101 - mae: 0.0683 - val_loss: 0.0209 - val_mse: 0.0209 - val_mae: 0.0902\n",
      "Epoch 31/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0098 - mse: 0.0098 - mae: 0.0674 - val_loss: 0.0205 - val_mse: 0.0205 - val_mae: 0.0884\n",
      "Epoch 32/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0096 - mse: 0.0096 - mae: 0.0666 - val_loss: 0.0200 - val_mse: 0.0200 - val_mae: 0.0873\n",
      "Epoch 33/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0093 - mse: 0.0093 - mae: 0.0662 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.0864\n",
      "Epoch 34/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0092 - mse: 0.0092 - mae: 0.0662 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.0854\n",
      "Epoch 35/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0090 - mse: 0.0090 - mae: 0.0657 - val_loss: 0.0189 - val_mse: 0.0189 - val_mae: 0.0841\n",
      "Epoch 36/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0089 - mse: 0.0089 - mae: 0.0658 - val_loss: 0.0184 - val_mse: 0.0184 - val_mae: 0.0838\n",
      "Epoch 37/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0088 - mse: 0.0088 - mae: 0.0653 - val_loss: 0.0185 - val_mse: 0.0185 - val_mae: 0.0822\n",
      "Epoch 38/150\n",
      "236/236 [==============================] - 0s 55us/sample - loss: 0.0086 - mse: 0.0086 - mae: 0.0648 - val_loss: 0.0181 - val_mse: 0.0181 - val_mae: 0.0818\n",
      "Epoch 39/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0085 - mse: 0.0085 - mae: 0.0649 - val_loss: 0.0178 - val_mse: 0.0178 - val_mae: 0.0818\n",
      "Epoch 40/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0085 - mse: 0.0085 - mae: 0.0647 - val_loss: 0.0178 - val_mse: 0.0178 - val_mae: 0.0808\n",
      "Epoch 41/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0084 - mse: 0.0084 - mae: 0.0643 - val_loss: 0.0176 - val_mse: 0.0176 - val_mae: 0.0805\n",
      "Epoch 42/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0083 - mse: 0.0083 - mae: 0.0643 - val_loss: 0.0174 - val_mse: 0.0174 - val_mae: 0.0803\n",
      "Epoch 43/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0083 - mse: 0.0083 - mae: 0.0645 - val_loss: 0.0172 - val_mse: 0.0172 - val_mae: 0.0803\n",
      "Epoch 44/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0082 - mse: 0.0082 - mae: 0.0641 - val_loss: 0.0173 - val_mse: 0.0173 - val_mae: 0.0794\n",
      "Epoch 45/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0081 - mse: 0.0081 - mae: 0.0636 - val_loss: 0.0172 - val_mse: 0.0172 - val_mae: 0.0790\n",
      "Epoch 46/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0081 - mse: 0.0081 - mae: 0.0634 - val_loss: 0.0171 - val_mse: 0.0171 - val_mae: 0.0787\n",
      "Epoch 47/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0080 - mse: 0.0080 - mae: 0.0631 - val_loss: 0.0170 - val_mse: 0.0170 - val_mae: 0.0784\n",
      "Epoch 48/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0080 - mse: 0.0080 - mae: 0.0630 - val_loss: 0.0169 - val_mse: 0.0169 - val_mae: 0.0784\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0079 - mse: 0.0079 - mae: 0.0631 - val_loss: 0.0168 - val_mse: 0.0168 - val_mae: 0.0782\n",
      "Epoch 50/150\n",
      "236/236 [==============================] - 0s 34us/sample - loss: 0.0079 - mse: 0.0079 - mae: 0.0628 - val_loss: 0.0169 - val_mse: 0.0169 - val_mae: 0.0775\n",
      "Epoch 51/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0078 - mse: 0.0078 - mae: 0.0623 - val_loss: 0.0167 - val_mse: 0.0167 - val_mae: 0.0775\n",
      "Epoch 52/150\n",
      "236/236 [==============================] - 0s 34us/sample - loss: 0.0078 - mse: 0.0078 - mae: 0.0629 - val_loss: 0.0165 - val_mse: 0.0165 - val_mae: 0.0780\n",
      "Epoch 53/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0077 - mse: 0.0077 - mae: 0.0624 - val_loss: 0.0168 - val_mse: 0.0168 - val_mae: 0.0767\n",
      "Epoch 54/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0077 - mse: 0.0077 - mae: 0.0615 - val_loss: 0.0168 - val_mse: 0.0168 - val_mae: 0.0764\n",
      "Epoch 55/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0077 - mse: 0.0077 - mae: 0.0615 - val_loss: 0.0165 - val_mse: 0.0165 - val_mae: 0.0767\n",
      "Epoch 56/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0076 - mse: 0.0076 - mae: 0.0616 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0767\n",
      "Epoch 57/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0076 - mse: 0.0076 - mae: 0.0616 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0764\n",
      "Epoch 58/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0075 - mse: 0.0075 - mae: 0.0609 - val_loss: 0.0167 - val_mse: 0.0167 - val_mae: 0.0756\n",
      "Epoch 59/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0075 - mse: 0.0075 - mae: 0.0607 - val_loss: 0.0166 - val_mse: 0.0166 - val_mae: 0.0755\n",
      "Epoch 60/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0075 - mse: 0.0075 - mae: 0.0605 - val_loss: 0.0165 - val_mse: 0.0165 - val_mae: 0.0756\n",
      "Epoch 61/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0075 - mse: 0.0075 - mae: 0.0603 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0755\n",
      "Epoch 62/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0074 - mse: 0.0074 - mae: 0.0602 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0756\n",
      "Epoch 63/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0074 - mse: 0.0074 - mae: 0.0600 - val_loss: 0.0164 - val_mse: 0.0164 - val_mae: 0.0752\n",
      "Epoch 64/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0074 - mse: 0.0074 - mae: 0.0599 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0752\n",
      "Epoch 65/150\n",
      "236/236 [==============================] - 0s 34us/sample - loss: 0.0074 - mse: 0.0074 - mae: 0.0596 - val_loss: 0.0165 - val_mse: 0.0165 - val_mae: 0.0746\n",
      "Epoch 66/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0074 - mse: 0.0074 - mae: 0.0599 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.0755\n",
      "Epoch 67/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0073 - mse: 0.0073 - mae: 0.0596 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0746\n",
      "Epoch 68/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0073 - mse: 0.0073 - mae: 0.0591 - val_loss: 0.0165 - val_mse: 0.0165 - val_mae: 0.0741\n",
      "Epoch 69/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0073 - mse: 0.0073 - mae: 0.0591 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.0748\n",
      "Epoch 70/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0072 - mse: 0.0072 - mae: 0.0592 - val_loss: 0.0160 - val_mse: 0.0160 - val_mae: 0.0749\n",
      "Epoch 71/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0072 - mse: 0.0072 - mae: 0.0590 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.0743\n",
      "Epoch 72/150\n",
      "236/236 [==============================] - 0s 34us/sample - loss: 0.0072 - mse: 0.0072 - mae: 0.0587 - val_loss: 0.0160 - val_mse: 0.0160 - val_mae: 0.0744\n",
      "Epoch 73/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0072 - mse: 0.0072 - mae: 0.0586 - val_loss: 0.0162 - val_mse: 0.0162 - val_mae: 0.0739\n",
      "Epoch 74/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0071 - mse: 0.0071 - mae: 0.0585 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0744\n",
      "Epoch 75/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0071 - mse: 0.0071 - mae: 0.0582 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.0738\n",
      "Epoch 76/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0071 - mse: 0.0071 - mae: 0.0580 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.0737\n",
      "Epoch 77/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0071 - mse: 0.0071 - mae: 0.0578 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0739\n",
      "Epoch 78/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0070 - mse: 0.0070 - mae: 0.0580 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0737\n",
      "Epoch 79/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0070 - mse: 0.0070 - mae: 0.0578 - val_loss: 0.0160 - val_mse: 0.0160 - val_mae: 0.0735\n",
      "Epoch 80/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0070 - mse: 0.0070 - mae: 0.0574 - val_loss: 0.0162 - val_mse: 0.0162 - val_mae: 0.0730\n",
      "Epoch 81/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0070 - mse: 0.0070 - mae: 0.0571 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.0731\n",
      "Epoch 82/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0069 - mse: 0.0069 - mae: 0.0572 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0736\n",
      "Epoch 83/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0070 - mse: 0.0070 - mae: 0.0577 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0736\n",
      "Epoch 84/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0069 - mse: 0.0069 - mae: 0.0570 - val_loss: 0.0161 - val_mse: 0.0161 - val_mae: 0.0728\n",
      "Epoch 85/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0070 - mse: 0.0070 - mae: 0.0567 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0726\n",
      "Epoch 86/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0069 - mse: 0.0069 - mae: 0.0573 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0737\n",
      "Epoch 87/150\n",
      "236/236 [==============================] - 0s 34us/sample - loss: 0.0069 - mse: 0.0069 - mae: 0.0572 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0732\n",
      "Epoch 88/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0069 - mse: 0.0069 - mae: 0.0565 - val_loss: 0.0162 - val_mse: 0.0162 - val_mae: 0.0724\n",
      "Epoch 89/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0069 - mse: 0.0069 - mae: 0.0560 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0726\n",
      "Epoch 90/150\n",
      "236/236 [==============================] - 0s 34us/sample - loss: 0.0068 - mse: 0.0068 - mae: 0.0563 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0732\n",
      "Epoch 91/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0068 - mse: 0.0068 - mae: 0.0565 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0728\n",
      "Epoch 92/150\n",
      "236/236 [==============================] - 0s 34us/sample - loss: 0.0068 - mse: 0.0068 - mae: 0.0561 - val_loss: 0.0160 - val_mse: 0.0160 - val_mae: 0.0724\n",
      "Epoch 93/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0068 - mse: 0.0068 - mae: 0.0556 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0724\n",
      "Epoch 94/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0068 - mse: 0.0068 - mae: 0.0556 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0727\n",
      "Epoch 95/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0068 - mse: 0.0068 - mae: 0.0559 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0724\n",
      "Epoch 96/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0068 - mse: 0.0068 - mae: 0.0556 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0723\n",
      "Epoch 97/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0068 - mse: 0.0068 - mae: 0.0554 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0723\n",
      "Epoch 98/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0067 - mse: 0.0067 - mae: 0.0552 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0721\n",
      "Epoch 99/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0067 - mse: 0.0067 - mae: 0.0554 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0722\n",
      "Epoch 100/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0067 - mse: 0.0067 - mae: 0.0551 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0720\n",
      "Epoch 101/150\n",
      "236/236 [==============================] - 0s 55us/sample - loss: 0.0067 - mse: 0.0067 - mae: 0.0549 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0721\n",
      "Epoch 102/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0067 - mse: 0.0067 - mae: 0.0551 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0723\n",
      "Epoch 103/150\n",
      "236/236 [==============================] - 0s 55us/sample - loss: 0.0067 - mse: 0.0067 - mae: 0.0550 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0719\n",
      "Epoch 104/150\n",
      "236/236 [==============================] - 0s 59us/sample - loss: 0.0067 - mse: 0.0067 - mae: 0.0545 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0718\n",
      "Epoch 105/150\n",
      "236/236 [==============================] - 0s 55us/sample - loss: 0.0067 - mse: 0.0067 - mae: 0.0546 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0722\n",
      "Epoch 106/150\n",
      "236/236 [==============================] - 0s 55us/sample - loss: 0.0067 - mse: 0.0067 - mae: 0.0547 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0719\n",
      "Epoch 107/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0544 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0718\n",
      "Epoch 108/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0543 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0719\n",
      "Epoch 109/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0544 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0719\n",
      "Epoch 110/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0542 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0718\n",
      "Epoch 111/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0540 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0718\n",
      "Epoch 112/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0539 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0717\n",
      "Epoch 113/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0543 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0719\n",
      "Epoch 114/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0539 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0716\n",
      "Epoch 115/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0532 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0716\n",
      "Epoch 116/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0535 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0718\n",
      "Epoch 117/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0542 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0717\n",
      "Epoch 118/150\n",
      "236/236 [==============================] - 0s 34us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0533 - val_loss: 0.0160 - val_mse: 0.0160 - val_mae: 0.0716\n",
      "Epoch 119/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0530 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0715\n",
      "Epoch 120/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0531 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0716\n",
      "Epoch 121/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0533 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0716\n",
      "Epoch 122/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0535 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0716\n",
      "Epoch 123/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0527 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0715\n",
      "Epoch 124/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0529 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0716\n",
      "Epoch 125/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0530 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0716\n",
      "Epoch 126/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0536 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0717\n",
      "Epoch 127/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0532 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0716\n",
      "Epoch 128/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0529 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0715\n",
      "Epoch 129/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0531 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0715\n",
      "Epoch 130/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0066 - mse: 0.0066 - mae: 0.0535 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0716\n",
      "Epoch 131/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0529 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0715\n",
      "Epoch 132/150\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.0072 - mse: 0.0072 - mae: 0.050 - 0s 51us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0523 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0714\n",
      "Epoch 133/150\n",
      "236/236 [==============================] - 0s 55us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0521 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0714\n",
      "Epoch 134/150\n",
      "236/236 [==============================] - 0s 51us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0527 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0716\n",
      "Epoch 135/150\n",
      "236/236 [==============================] - 0s 47us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0525 - val_loss: 0.0157 - val_mse: 0.0157 - val_mae: 0.0714\n",
      "Epoch 136/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0518 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0714\n",
      "Epoch 137/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0520 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0716\n",
      "Epoch 138/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0524 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0714\n",
      "Epoch 139/150\n",
      "236/236 [==============================] - 0s 34us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0519 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0714\n",
      "Epoch 140/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0519 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0713\n",
      "Epoch 141/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0521 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0715\n",
      "Epoch 142/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0524 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.0714\n",
      "Epoch 143/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0517 - val_loss: 0.0158 - val_mse: 0.0158 - val_mae: 0.0714\n",
      "Epoch 144/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0065 - mse: 0.0065 - mae: 0.0529 - val_loss: 0.0151 - val_mse: 0.0151 - val_mae: 0.0717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 145/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0524 - val_loss: 0.0155 - val_mse: 0.0155 - val_mae: 0.0713\n",
      "Epoch 146/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0516 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0713\n",
      "Epoch 147/150\n",
      "236/236 [==============================] - 0s 34us/sample - loss: 0.0064 - mse: 0.0064 - mae: 0.0520 - val_loss: 0.0152 - val_mse: 0.0152 - val_mae: 0.0714\n",
      "Epoch 148/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0063 - mse: 0.0063 - mae: 0.0520 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0713\n",
      "Epoch 149/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0063 - mse: 0.0063 - mae: 0.0519 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0714\n",
      "Epoch 150/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0063 - mse: 0.0063 - mae: 0.0518 - val_loss: 0.0154 - val_mse: 0.0154 - val_mae: 0.0712\n"
     ]
    }
   ],
   "source": [
    "#fitting model\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)\n",
    "end_time = time.time()\n",
    "ANN_time = end_time - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "#Vizualize Model\n",
    "plot_model(model, to_file='ANN_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deZycZZnv/89V1fve6XS2TkICBshCTGKLOAiCLAKOgIoSRz3gcWRcOLiMM6LOkZE5/o4zehx0BhUc8agHQYwiOSPIjstBMAlLIIFIIIF0Akkn6X3vruv3x/10d3VT3alOurqa1Pf9etWrqp71qifp+tb9LPdj7o6IiMhosWwXICIi05MCQkREUlJAiIhISgoIERFJSQEhIiIpKSBERCQlBYTIJDCz/21m/yPNaXea2dlHuhyRTFNAiIhISgoIERFJSQEhOSPatfN3ZrbZzDrM7AdmNtvM7jKzNjO7z8yqk6a/0My2mFmzmT1kZkuTxq02s8ei+X4GFI1a11+a2RPRvA+b2crDrPmjZrbdzA6a2XozmxcNNzP7VzPbZ2Yt0WdaEY27wMy2RrXtNrPPHdYGk5yngJBc8x7gHOB44J3AXcAXgZmEv4erAMzseOAW4NNALXAn8H/NrMDMCoBfAT8BZgA/j5ZLNO8a4Cbgb4Aa4AZgvZkVTqRQM3sb8D+B9wFzgReBW6PR5wKnR5+jCrgUOBCN+wHwN+5eDqwAHpjIekUGKSAk1/ybu+91993A74FH3f1xd+8BbgdWR9NdCvza3e919z7gG0Ax8BfAKUA+cJ2797n7OmBD0jo+Ctzg7o+6+4C7/wjoieabiA8AN7n7Y1F9XwDebGaLgD6gHDgRMHd/xt1fjubrA5aZWYW7N7n7YxNcrwiggJDcszfpdVeK92XR63mEX+wAuHsC2AXUReN2+8ieLl9Men0M8LfR7qVmM2sGFkTzTcToGtoJrYQ6d38A+HfgemCvmd1oZhXRpO8BLgBeNLPfmtmbJ7heEUABITKWPYQveiDs8yd8ye8GXgbqomGDFia93gV81d2rkh4l7n7LEdZQSthltRvA3b/t7m8AlhN2Nf1dNHyDu18EzCLsCrttgusVARQQImO5DXiHmZ1lZvnA3xJ2Ez0M/BHoB64yszwzezdwctK83wc+ZmZvig4ml5rZO8ysfII1/BT4sJmtio5f/H+EXWI7zeyN0fLzgQ6gGxiIjpF8wMwqo11jrcDAEWwHyWEKCJEU3H0b8EHg34D9hAPa73T3XnfvBd4NXA40EY5X/DJp3o2E4xD/Ho3fHk070RruB/478AtCq+U4YG00uoIQRE2E3VAHCMdJAD4E7DSzVuBj0ecQmTDTDYNERCQVtSBERCQlBYSIiKSkgBARkZQUECIiklJetguYLDNnzvRFixZluwwRkdeUTZs27Xf32lTjjpqAWLRoERs3bsx2GSIirylm9uJY4zK6i8nMzjOzbVFvlFenGP8xM3sq6vXyD2a2LGncF6L5tpnZ2zNZp4iIvFrGAsLM4oR+Ys4HlgHvTw6AyE/d/SR3XwX8C/DNaN5lhAuClgPnAd+JliciIlMkky2Ik4Ht7v5CdOXprcBFyRO4e2vS21Jg8Kq9i4Bb3b3H3XcQrkRN7spAREQyLJPHIOoInZYNagDeNHoiM/sk8FmgAHhb0ryPjJq3LsW8VwBXACxcuHD0aPr6+mhoaKC7u/vwPoG8SlFREfPnzyc/Pz/bpYhIhmUyICzFsFf16+Hu1wPXm9lfAf8AXDaBeW8EbgSor69/1fiGhgbKy8tZtGgRIzvelMPh7hw4cICGhgYWL16c7XJEJMMyuYupgdA98qD5hO6Lx3IrcPFhzptSd3c3NTU1CodJYmbU1NSoRSaSIzIZEBuAJWa2OLpF41pgffIEZrYk6e07gOei1+uBtWZWaGaLgSXAnw6nCIXD5NL2FMkdGdvF5O79ZnYlcDcQJ9w6cYuZXQtsdPf1wJVmdjbhFolNhN1LRNPdBmwl9Lv/SXfPSJ/2A4kE+9t7KS/Ko6TgqLksRETkiGX0Ogh3v9Pdj3f349z9q9GwL0fhgLt/yt2Xu/sqdz/T3bckzfvVaL4T3P2uzNUIe1u76ejJzD1Vmpub+c53vjPh+S644AKam5szUJGISHpyvi+meCzsMhnI0H0xxgqIgYHxA+nOO++kqqoqIzWJiKQj5/epmBnxmJFIZCYgrr76ap5//nlWrVpFfn4+ZWVlzJ07lyeeeIKtW7dy8cUXs2vXLrq7u/nUpz7FFVdcAQx3HdLe3s7555/PW97yFh5++GHq6uq44447KC4uzki9IiKDciYgvvJ/t7B1T2vKcZ29A8RjRmHexBpUy+ZVcM07l487zde+9jWefvppnnjiCR566CHe8Y538PTTTw+dJnrTTTcxY8YMurq6eOMb38h73vMeampqRizjueee45ZbbuH73/8+73vf+/jFL37BBz+ou0iKSGblTECMxyyc4z8VTj755BHXEHz729/m9ttvB2DXrl0899xzrwqIxYsXs2rVKgDe8IY3sHPnzimpVURyW84ExHi/9F9obCfh8LpZZRmvo7S0dOj1Qw89xH333ccf//hHSkpKOOOMM1JeY1BYWDj0Oh6P09XVlfE6RURy/iA1hAPVAxk6BlFeXk5bW1vKcS0tLVRXV1NSUsKzzz7LI488knI6EZFsyJkWxHgyGRA1NTWceuqprFixguLiYmbPnj007rzzzuN73/seK1eu5IQTTuCUU07JSA0iIofDpmrfe6bV19f76BsGPfPMMyxduvSQ877c0sX+9l5WzKvQlcJpSHe7isj0Z2ab3L0+1TjtYiK0INydDDUiRERekxQQQDxqNWRqN5OIyGuRAgLIiykgRERGU0CQ+e42REReixQQJAWEWhAiIkMUECggRERSUUAAsWkUEGVl4WruPXv2cMkll6Sc5owzzmD0Kb2jXXfddXR2dg69V/fhIjJRCgjCWUzG9AiIQfPmzWPdunWHPf/ogFD34SIyUQoIQpffsQxdTf35z39+xP0g/vEf/5GvfOUrnHXWWaxZs4aTTjqJO+6441Xz7dy5kxUrVgDQ1dXF2rVrWblyJZdeeumIvpg+/vGPU19fz/Lly7nmmmuA0AHgnj17OPPMMznzzDOB0H34/v37AfjmN7/JihUrWLFiBdddd93Q+pYuXcpHP/pRli9fzrnnnqs+n0RyXO50tXHX1fDKUylGOPT3cFwiBrE45MXTX+ack+D8r407ydq1a/n0pz/NJz7xCQBuu+02fvOb3/CZz3yGiooK9u/fzymnnMKFF1445lXc3/3udykpKWHz5s1s3ryZNWvWDI376le/yowZMxgYGOCss85i8+bNXHXVVXzzm9/kwQcfZObMmSOWtWnTJn74wx/y6KOP4u686U1v4q1vfSvV1dXqVlxERlALAiDRR4wEmTjLdfXq1ezbt489e/bw5JNPUl1dzdy5c/niF7/IypUrOfvss9m9ezd79+4dcxm/+93vhr6oV65cycqVK4fG3XbbbaxZs4bVq1ezZcsWtm7dOm49f/jDH3jXu95FaWkpZWVlvPvd7+b3v/89oG7FRWSk3GlBjPVL3x1efoKO2AwOxGoy0uX3JZdcwrp163jllVdYu3YtN998M42NjWzatIn8/HwWLVqUspvvZKlaFzt27OAb3/gGGzZsoLq6mssvv/yQyxmv7y11Ky4iydSCMAOLk2eJjB2kXrt2Lbfeeivr1q3jkksuoaWlhVmzZpGfn8+DDz7Iiy++OO78p59+OjfffDMATz/9NJs3bwagtbWV0tJSKisr2bt3L3fdddfQPGN1M3766afzq1/9is7OTjo6Orj99ts57bTTJvHTisjRIndaEOOJxYmTuYBYvnw5bW1t1NXVMXfuXD7wgQ/wzne+k/r6elatWsWJJ5447vwf//jH+fCHP8zKlStZtWoVJ598MgCvf/3rWb16NcuXL+fYY4/l1FNPHZrniiuu4Pzzz2fu3Lk8+OCDQ8PXrFnD5ZdfPrSMv/7rv2b16tXanSQir6LuvgEan6U7EeO5vtmsqFOX34ei7r5Fjh7q7vtQLE7cEzjq8ltEZJACAiCWhzEAwEAikeViRESmh6M+INLahRaLE/MQDNPpaurp6GjZJSkih5bRgDCz88xsm5ltN7OrU4z/rJltNbPNZna/mR2TNG7AzJ6IHusPZ/1FRUUcOHDg0F9qsTjmgy0IfQGOxd05cOAARUVF2S5FRKZAxs5iMrM4cD1wDtAAbDCz9e6efCXX40C9u3ea2ceBfwEujcZ1ufuqI6lh/vz5NDQ00NjYOP6E3a3Q3cw+H6D/QCHFBRO4mjrHFBUVMX/+/GyXISJTIJOnuZ4MbHf3FwDM7FbgImAoINz9waTpHwEmtV+H/Px8Fi9efOgJN94Ed3+Gy7qv57PvPp21r184mWWIiLwmZXIXUx2wK+l9QzRsLB8B7kp6X2RmG83sETO7ONUMZnZFNM3GQ7YSxlNUCUClddDS1Xf4yxEROYpksgWR6mKClDv4zeyDQD3w1qTBC919j5kdCzxgZk+5+/MjFuZ+I3AjhOsgDrvSotANdrW109qtgBARgcy2IBqABUnv5wN7Rk9kZmcDXwIudPeeweHuvid6fgF4CFidsUqLQ0DMKeyhtas/Y6sREXktyWRAbACWmNliMysA1gIjzkYys9XADYRw2Jc0vNrMCqPXM4FTSTp2MemiFsSc/G61IEREIhnbxeTu/WZ2JXA3EAducvctZnYtsNHd1wNfB8qAn0fdW7zk7hcCS4EbzCxBCLGvjTr7aXIVVwMwM6+LP+sYhIgIkOHO+tz9TuDOUcO+nPT67DHmexg4KZO1jRAdpK7J66JVASEiAuTAldRpicWhsILqWAet3ToGISICCohhRVVU0qnTXEVEIgqIQcWVlNOuXUwiIhEFxKCiKsoS7fT0J+juG8h2NSIiWaeAGFRUSUki3KKzTcchREQUEEOKqyjsDwGh4xAiIgqIYUVVFPS1AuhiORERFBDDiquID3RTQJ8OVIuIoIAYFnW3UaFTXUVEAAXEsKi7jUpr18VyIiIoIIZFLYhKOrSLSUQEBcQw9cckIjKCAmJQdE+I2eryW0QEUEAMi3Yxzcrv0k2DRERQQAyLWhAz8zrVghARQQExLJ4P+aXMiHXpNFcRETJ8w6DXnOLQ5bcOUouIqAUxUlGVroMQEYkoIJIVV1GW6KClqw93z3Y1IiJZpYBIVlRFSaKNgYTT2at7QohIblNAJCuqpHggdPmtM5lEJNcpIJIVV1HYH3X5rWshRCTHKSCSFVWR199JHv061VVEcp4CIlnxcJffOtVVRHKdAiLZYI+u1qFjECKS8zIaEGZ2npltM7PtZnZ1ivGfNbOtZrbZzO43s2OSxl1mZs9Fj8syWeeQoRZEh3YxiUjOy1hAmFkcuB44H1gGvN/Mlo2a7HGg3t1XAuuAf4nmnQFcA7wJOBm4xsyqM1XrkOQWhA5Si0iOy2QL4mRgu7u/4O69wK3ARckTuPuD7t4ZvX0EmB+9fjtwr7sfdPcm4F7gvAzWGkQtiFl5XdrFJCI5L5MBUQfsSnrfEA0by0eAuyYyr5ldYWYbzWxjY2PjEZbL0E2DZhV0axeTiOS8TAaEpRiWsv8KM/sgUA98fSLzuvuN7l7v7vW1tbWHXeiQaBdTbVx3lRMRyWRANAALkt7PB/aMnsjMzga+BFzo7j0TmXfS5RdBXhE1cd0TQkQkkwGxAVhiZovNrABYC6xPnsDMVgM3EMJhX9Kou4Fzzaw6Ojh9bjQs84qqqI516iC1iOS8jN0Pwt37zexKwhd7HLjJ3beY2bXARndfT9ilVAb83MwAXnL3C939oJn9EyFkAK5194OZqnWE4ioqu3Waq4hIRm8Y5O53AneOGvblpNdnjzPvTcBNmatuDEVVlHXrQjkREV1JPVpxFaWJdtp7+kkkdE8IEcldCojRiqooGWjDHdp0ZzkRyWEKiNGKqyjs1z0hREQUEKMVVVLQ30aMhA5Ui0hOU0CMFl0sV46uhRCR3KaAGK04ucM+BYSI5C4FxGiDPbqiHl1FJLcpIEYr1k2DRERAAfFqSfeE0EFqEcllCojRohbE7PxuHYMQkZymgBhtsMvv/C5adaGciOQwBcRo+cUQL6A23qldTCKS0xQQo5lBcTUzYjrNVURymwIileIZVOksJhHJcQqIVIqrqaRd10GISE5TQKRSXE1Zok3HIEQkpykgUimupmSgja6+AXr7E9muRkQkKxQQqRRXUdTfAkCbjkOISI5SQKRSMoP8RDeF9Go3k4jkLAVEKsXVQNRhny6WE5EcpYBIJQqIKmvXtRAikrMUEKkMBgTtuhZCRHKWAiKVpBaEjkGISK5KKyDM7FNmVmHBD8zsMTM7N9PFZc2IXUw6BiEiuSndFsR/dfdW4FygFvgw8LWMVZVtxTMAqInpnhAikrvSDQiLni8AfujuTyYNO/oUlEIsn1l5XQoIEclZ6QbEJjO7hxAQd5tZOXDIS4zN7Dwz22Zm283s6hTjT492V/Wb2SWjxg2Y2RPRY32adU6OqEfX2rxOmjt7p3TVIiLTRV6a030EWAW84O6dZjaDsJtpTGYWB64HzgEagA1mtt7dtyZN9hJwOfC5FIvocvdVadY3+YqrqenvoLlTLQgRyU3ptiDeDGxz92Yz+yDwD0DLIeY5Gdju7i+4ey9wK3BR8gTuvtPdN5NGa2TKFVdTZR00qQUhIjkq3YD4LtBpZq8H/h54EfjxIeapA3YlvW+IhqWryMw2mtkjZnZxqgnM7Ipomo2NjY0TWHQaiqupRD26ikjuSjcg+t3dCS2Ab7n7t4DyQ8yT6iC2T6C2he5eD/wVcJ2ZHfeqhbnf6O717l5fW1s7gUWnoWQGpYk2tSBEJGelGxBtZvYF4EPAr6PjC/mHmKcBWJD0fj6wJ93C3H1P9PwC8BCwOt15J0VxNSX9rXT3JejuG5jSVYuITAfpBsSlQA/heohXCLuKvn6IeTYAS8xssZkVAGuBtM5GMrNqMyuMXs8ETgW2jj/XJCuuIj/RRQF9OlAtIjkprYCIQuFmoNLM/hLodvdxj0G4ez9wJXA38Axwm7tvMbNrzexCADN7o5k1AO8FbjCzLdHsS4GNZvYk8CDwtVFnP2VeUo+uzV3azSQiuSet01zN7H2EFsNDhGML/2Zmf+fu68abz93vBO4cNezLSa83EHY9jZ7vYeCkdGrLmMGAsHaaOtSCEJHck+51EF8C3uju+wDMrBa4Dxg3IF7TooCopp0WtSBEJAelewwiNhgOkQMTmPe1KeqPqcraadIxCBHJQem2IH5jZncDt0TvL2XUrqOjTlKPrjpILSK5KK2AcPe/M7P3EM4mMuBGd789o5VlWxQQNTH1xyQiuSndFgTu/gvgFxmsZXopLIdYHnNinTyjFoSI5KBxA8LM2kh99bMB7u4VGalqOjCDkhpm9XTwsFoQIpKDxg0Idz9UdxpHt9JaavtadQxCRHLS0X0m0pEqnckMWnShnIjkJAXEeEprqfQWneYqIjlJATGe0lrK+5to6ewjdGYrIpI7FBDjKZ1JYaKT2EAXnb3q0VVEcosCYjyl4R4TNbTSrBsHiUiOUUCMZzAgrJWmDh2oFpHcooAYT1JA6NajIpJrFBDjKZ0JwExr0a1HRSTnKCDGk3wMQqe6ikiOUUCMp6AUzy+hxlrVYZ+I5BwFxCFY6Uxmx9p0sZyI5BwFxKGUzmJ2XpvOYhKRnKOAOJTSWmqtlf0KCBHJMQqIQymdSTUt7G/ryXYlIiJTSgFxKKW1VAw0s7+tO9uViIhMKQXEoZTWEmeA/s4mEgl12CciuUMBcSjRtRBV3qKrqUUkpyggDiW6mrqGVg506DiEiOSOjAaEmZ1nZtvMbLuZXZ1i/Olm9piZ9ZvZJaPGXWZmz0WPyzJZ57iS+mNqbNOZTCKSOzIWEGYWB64HzgeWAe83s2WjJnsJuBz46ah5ZwDXAG8CTgauMbPqTNU6riggZloL+9vVghCR3JHJFsTJwHZ3f8Hde4FbgYuSJ3D3ne6+GUiMmvftwL3uftDdm4B7gfMyWOvYSmqAaBeTAkJEckgmA6IO2JX0viEaNmnzmtkVZrbRzDY2NjYedqHjiufhxTOYFWtmf7t2MYlI7shkQFiKYemeJ5rWvO5+o7vXu3t9bW3thIqbCKuoY0Fes3YxiUhOyWRANAALkt7PB/ZMwbyTr7KOOjuoFoSI5JRMBsQGYImZLTazAmAtsD7Nee8GzjWz6ujg9LnRsOyoqGM2+9WCEJGckrGAcPd+4ErCF/szwG3uvsXMrjWzCwHM7I1m1gC8F7jBzLZE8x4E/okQMhuAa6Nh2VE5n7JEGx3tLVkrQURkquVlcuHufidw56hhX056vYGw+yjVvDcBN2WyvrRVhhLz21/OciEiIlNHV1KnoyKcQDVjoJGOnv4sFyMiMjUUEOmoDAExz/ZzQAeqRSRHKCDSUT4Px5hnB2jUgWoRyREKiHTkFdBfUstcDupMJhHJGQqINHlFHXPtgHYxiUjOUECkKa9qAfPsgFoQIpIzFBBpilUtoC52gAO69aiI5AgFRLoq6yimh9bmDHUKKCIyzSgg0hVdC9HftOsQE4qIHB0UEOmKrqa21uz1GSgiMpUUEOmKAqKidy+dvbqaWkSOfgqIdJXOImF5zLMD7G7qynY1IiIZp4BIVyxGb9k8Ftg+djcrIETk6KeAmIiZJ7DEdisgRCQnKCAmoGDeCo6zPbx8oDXbpYiIZJwCYgJis5eTbwP0N/4526WIiGScAmIiZi0FoPDgtiwXIiKSeQqIiZh5PAPEqW7fnu1KREQyTgExEXkFNBUvZH7vDvoGEtmuRkQkoxQQE9RZdTzH2y5eaVGnfSJydFNATJDXLmNhrJE9+9Rpn4gc3RQQE1Q0fwUAHQ1bslyJiEhmKSAmqGrRKgASryggROTopoCYoMKZx9JFIYVNz2a7FBGRjFJATFQsxo78JdS1PJbtSkREMkoBcRheqj2DY/tfIHFgR7ZLERHJmIwGhJmdZ2bbzGy7mV2dYnyhmf0sGv+omS2Khi8ysy4zeyJ6fC+TdU5U7/EXANDy+O1ZrkREJHMyFhBmFgeuB84HlgHvN7Nloyb7CNDk7q8D/hX456Rxz7v7qujxsUzVeTgWHrecrYlj8Gf+M9uliIhkTCZbECcD2939BXfvBW4FLho1zUXAj6LX64CzzMwyWNOkOGF2Ofck6qk+8Bi078t2OSIiGZHJgKgDdiW9b4iGpZzG3fuBFqAmGrfYzB43s9+a2WmpVmBmV5jZRjPb2Ng4dReuFRfEearidAyHZ389ZesVEZlKmQyIVC0BT3Oal4GF7r4a+CzwUzOreNWE7je6e72719fW1h5xwRNRVHcSu2wubPgB9PdM6bpFRKZCJgOiAViQ9H4+sGesacwsD6gEDrp7j7sfAHD3TcDzwPEZrHXCls2r5J961sLep+Dea7JdjojIpMtkQGwAlpjZYjMrANYC60dNsx64LHp9CfCAu7uZ1UYHuTGzY4ElwAsZrHXCTpxTzj2JN7J36Yfh0e/C4zdDQj28isjRI2MBER1TuBK4G3gGuM3dt5jZtWZ2YTTZD4AaM9tO2JU0eCrs6cBmM3uScPD6Y+5+MFO1Ho6lc8Mer/vmfxLq6uGOT8C3Xw/3fhm23QVdTVmuUETkyJj76MMCr0319fW+cePGKVufu7Pq2nu54KS5/M93LoFn/xMe/wns/AMk+iGWB4tOg5WXwsr3QSw+ZbWJiKTLzDa5e32qcXlTXczRwsxYOb+SP+04APknwUmXhEdvJ+x5DJ67F55ZD7/6GPy/b8E518KSc2D6n8UrIgKoq40jctaJs3i+sYMd+zuGBxaUwKK3wDlfgf/2GLz3RzDQAz99L/zonbBbfTiJyGuDAuIInLV0NgD3P7M39QRmsPxi+MSjcP6/wL6t8P0z4Wcfgn3qDVZEpjcFxBFYMKOEE+eUc+/WMQJiUF4BvOlv4KrH4a2fh+cfgO+cAr+8Ag5Oq5OzRESGKCCO0DnLZrPxxSaaOnoPPXFRJZz5RfjUZviLK2HrHfDtNfDji+DJn0Fvx6GXISIyRRQQR+jspbMZSDgP/XkCfTKV1sC5/wOuegLe+vdwcAfcfgV8fQnc/vHQwkgMZK5oEZE0KCCO0El1lcwqL+T2x/cw4VOGK+aGFsVVT8CH74KT3hNOl/3Ju+B/nQh3XQ0Nm+AoORVZRF5bFBBHKBYzPvKWxfzuz43c+LvDPJ4Qi8ExfwEX/ht87jl4309g4Smw8Sb4j7fBt1fDA1+Flt2TW7yIyDh0odwkcHf+2y2P8+unXub7H6rn7GWzJ2fBXc2hRfHUz2HH78DicNJ7YfUHYeGbQ7CIiByB8S6UU0BMkq7eAd57w8Ns2dPKZW9exOfefgJlhZN4HWLTTvjjd8LV2n2dUD4PVrwbVrwH5q3WBXgiclgUEFOkrbuPb9y9jR8/8iKlBXmcfvxMzjpxNmeeOIsZpQWTs5Kedvjzb+CpdbD9Pkj0wYxjQ1AseXsIi7gukBeR9CggptiTu5q5dcNL3P/MPva19RAzqF80g3evruOClXOpKMqfnBV1Hox2Qa2Dnb8HT0BBWTieseg0WHwazFmpfqBEZEwKiCxJJJyn97Rw3zP7+PXmPTzf2EFBXoxzls3mXavqeMuSmRTlT9KXd8f+EBI7fh+e9/85DC+qhGPeEsJi4Skwa3m4cE9EBAXEtODubG5o4ZePNbD+yT00dfZRWhDnjBNmce7y2ZxxwiwqiyepZQHQ+nLoWXbHb0NgNO0Mw+MFUPM6qF4MM6LH4OvKhdo9JZJjFBDTTG9/gv/3/H7u3bqXe7fupbGth7yY8ebjajh3+RzOWTqbOZVFk7vS5l2weyPseRz2Pxe6+GjaCf3dw9PE8qByQVJoHBtel80O12LE86FyPpTU6KC4yFFCATGNJRLO47uauWfrK9yzZe9Qz7CrFlRx7vLZnLtsDq+bVZaplUP7K+FK7oMvQNOO8Lopet/dknq+vCKoqIOyWWCxECxFFVBUBcVVw8+FldGpuFGYWAzyCsP8eUWQXwR5xTjc4x4AAA67SURBVGFYfvScGICB3vB+aP5Ifw/0dYXX+SXaVSYyCRQQrxHuzvZ97dyzdS/3bHmFJxvCF/RxtaWcu3wOZ504i9ULq4nHpujXe+fBEBYdB8KXe18ntO6B1oZw0V5HY2hZJPpCmHQ1Q3fzyFbJEbHhwOltD+tLVlIDhRXhILzFw3NfV5iurzMKosLUz7H8UPdAX/TcH54xqF4EVQvCGWNdB8N26G2HinlhXEFZCMX+nrCeeEFYbl8ndLdCYRmUzgo3juppDc+Dn8eM4cC0pGFJ4/NLoHwulMwIn2mgD9r3Qfve8NkSA+FstVlLw+uupnDMqW1P2CZls8OjpCaM7++OHj3heaAPCsvDtvVEGD7QGx5Y+GyxvLDuWHz4s/a0hv8HBWVh/oKysM3aG8P28YEQ+OWzIb80DOtpDdvRB8K/Y1FFWJ4nwvD+7vB54wXQ2xbWUzoLiqvD521/JdxjJdEP1ceE3aMWD9u6aWf4/xkvDJ+1ZAYUzwi7Sd3DZ/do+7S9En50VC4I0yX/X+huCT+I+rvDdssrDMMsFlrSBSVhfNsroQ6LhfWU1EDpzNCyPvA8tDSEz5ZfPPwDqrc9/F0M9ITtPtAXaiqbE/6PJfrDuppfCo/qReEOlRaDlpfCuP7e8G9VtTB81r5OwEPtif7h7Vs+5/D+yhQQr017mru475m93LNlL4+8cID+hFNdks9bj6/lbUtn89YltVSWTOJxi8nS1x2Cors1fBEA4MNfRoNfWH3dSV9e0ftYXviD6+sKf9hdTWFZ+SXhj66wPCyrpy38wfa2D38RJAbCH03Z7PBHOtCTtL6eV39JDq4rXjD8OtEfvgxadod1DX7pFJRC625oejHUluiLWkHFYVl9XeGLpLAidLrYuR+w8IUYL4i6S/GkblN8eBiMfN3bkRQqSeKF4UvHE6GWZBaD0tqwvQbS6DhSpq/BL/5U/wfGMv9k+Ot7D2t1CoijQEtXH79/rpEHnt3HQ9saOdjRSzxmvGFhNaccV0P9MdWsXlhF+WSdQitHJpEIrYHDOVaTSEDngfBl7wMhvEprwxlpg8trfRkObA+/dgvLwy/d/KIQNF1N4dd358EQeqlaTz2tIXgtHobHC8KD6Jd3oj/puT/MV1g2/Mu/tyP84o/lh9oKy4Z/2bfvDc8F5aG2wXFdTSHYfQCwMG6w5dXfG70vCC2SroOhJVExN4QzFloLB54PYZhfHH5RVy8KAd11MGyzzmibWSza/rHQcimfE0K8efBXeU/4AdHXHeqbcVzYfu37wriiyvAj4OCO8FlrjgstyHhB2C6dB4Yf/d3heF3VMWHdvR1RC3tf+ExFVWH7xfOibWzhx03LrvC+qCIc26tcAI3PwosPh+lnHBtaKXkF4XM17Qw15ZeEz9bfG1p4BWVh/hMvOKz/qgqIo8xAwnmyoZkHn93Hg9v2sXVPKwmHmMEJcyo4qa6CE+dUcOLcck6cUzF5F+mJyFFHAXGUa+/p5/GXmti4s4lNLzax9eVWDibdn6KyOJ/51cXUVRUzv7qEuupi5lcXM6u8kOqSAqpLCigvyiM2Vcc2RGTaGC8gdNL7UaCsMI/TltRy2pJaIBzsbmzv4dmX29j2ShsvHuxgd1MXO/Z38Pvn9tPV9+p7TcQMqkoKqCrOp6I4n5KCePTIG/FcXBCnOD9OQV4sPOIx8uPhdX7choaF96+eJm5GLAbxmBEzIx6zaJjCSWS6UUAchcyMWeVFzCov4vTja0eMc3eaOvtoaOqksa2H5s4+mjp7ae7so7mrl6bOPlq7+ujqHaC5s4/O3n46eweiRz+JDDY4h8OCodBIDpB4FCgjxg8OMyMvPjp0UgfR8HKMuJFimCXNR4pho8YnDbNo+8fMMAvBaxaGx6KaYtFxhFga0w0/wiHsnv4B+gb8VfUObpPBYbGkZQ0ethheV3gerHVo2Ojpo88T/k9Fz9GQ4fcMvTBGLTdpXgsTjDs++XBN8vqS12XRG0ueRtfkZIwCIseYGTNKCw7ruIS709OfoKt3gL6BBL0DCXr7E/QNOL394X3f0LDE0LDhaQYY8HDtx4A7Awkfej08DBLRuIGED70eHpY0fnC+xPD7EfMkoG8gMWr+5GUyznqSxifVd5TskT1qDQZQeJ0iTBieYPTwsYJo8EXycg8VWoxa3nBtlvR6ZJ1Dw8eoaWjdKWpaOreCf/+rNWNvmMOkgJC0mRlF+fHJ6z/qNchHhBMjgi7hIVScECQJH/s5tMTC81jjw/voddR0K8yPkxezUYHGyHBzDycjJS+XcIKTR68Hx3n0mV5VZzQchs/MHTpBd+j98HiPXiSvZ3Ce5PUMTz9y3tHDkrf3iHWMMf/gm1Q1Jtc/ovYRw1OvZ/QyRtSUxnpIrvNwaxrxuYdrSF7FwhklZEJGA8LMzgO+BcSB/3D3r40aXwj8GHgDcAC41N13RuO+AHwEGACucve7M1mrSDos2pWlX1aSCzJ2SzIziwPXA+cDy4D3m9myUZN9BGhy99cB/wr8czTvMmAtsBw4D/hOtDwREZkimbxn5cnAdnd/wd17gVuBi0ZNcxHwo+j1OuAsCzvkLgJudfced98BbI+WJyIiUySTAVEH7Ep63xANSzmNu/cDLUBNmvNiZleY2UYz29jY2Dh6tIiIHIFMBkSqc89GnwMy1jTpzIu73+ju9e5eX1tbm2IWERE5XJkMiAZgQdL7+cCesaYxszygEjiY5rwiIpJBmQyIDcASM1tsZgWEg87rR02zHrgsen0J8ICHc7vWA2vNrNDMFgNLgD9lsFYRERklY2fruXu/mV0J3E04zfUmd99iZtcCG919PfAD4Cdmtp3QclgbzbvFzG4DtgL9wCfd/dX9Q4iISMaosz4RkRyWE725mlkj8OIRLGImsH+SysmU6V7jdK8PVONkUY2TYzrUeIy7pzzL56gJiCNlZhvHStHpYrrXON3rA9U4WVTj5JjuNWbyILWIiLyGKSBERCQlBcSwG7NdQBqme43TvT5QjZNFNU6OaV2jjkGIiEhKakGIiEhKCggREUkp5wPCzM4zs21mtt3Mrs52PQBmtsDMHjSzZ8xsi5l9Kho+w8zuNbPnoufqaVBr3MweN7P/jN4vNrNHoxp/FnWzks36qsxsnZk9G23PN0+n7Whmn4n+jZ82s1vMrGg6bEMzu8nM9pnZ00nDUm43C74d/Q1tNrPJv/dlevV9Pfp33mxmt5tZVdK4L0T1bTOzt2e6vrFqTBr3OTNzM5sZvZ/ybZiOnA6ING9qlA39wN+6+1LgFOCTUV1XA/e7+xLg/uh9tn0KeCbp/T8D/xrV2ES4KVQ2fQv4jbufCLyeUOu02I5mVgdcBdS7+wpClzRrmR7b8H8TbtaVbKztdj6hv7QlwBXAd7NU373ACndfCfwZ+AJk9QZkqWrEzBYA5wAvJQ3OxjY8pJwOCNK7qdGUc/eX3f2x6HUb4UutjpE3WPoRcHF2KgzMbD7wDuA/ovcGvI1w8yfIco1mVgGcTujzC3fvdfdmptd2zAOKo96MS4CXmQbb0N1/R+gfLdlY2+0i4McePAJUmdncqa7P3e+J7isD8AihF+jB+qb8BmRjbEMId8/8e0bewmDKt2E6cj0g0roxUTaZ2SJgNfAoMNvdX4YQIsCs7FUGwHWE/+iJ6H0N0Jz0R5rt7Xks0Aj8MNoN9h9mVso02Y7uvhv4BuGX5MuEG2ZtYnptw2Rjbbfp+Hf0X4G7otfTpj4zuxDY7e5Pjho1bWpMlusBkdaNibLFzMqAXwCfdvfWbNeTzMz+Etjn7puSB6eYNJvbMw9YA3zX3VcDHUyP3XIARPvwLwIWA/OAUsKuhtGmzf/JMUyrf3cz+xJhN+3Ng4NSTDbl9ZlZCfAl4MupRqcYlvV/91wPiGl7YyIzyyeEw83u/sto8N7BZmf0vC9b9QGnAhea2U7Crrm3EVoUVdHuEsj+9mwAGtz90ej9OkJgTJfteDaww90b3b0P+CXwF0yvbZhsrO02bf6OzOwy4C+BD/jwRV7Tpb7jCD8Gnoz+buYDj5nZHKZPjSPkekCkc1OjKRfty/8B8Iy7fzNpVPINli4D7pjq2ga5+xfcfb67LyJstwfc/QPAg4SbP0H2a3wF2GVmJ0SDziLcY2S6bMeXgFPMrCT6Nx+sb9psw1HG2m7rgf8SnYlzCtAyuCtqKpnZecDngQvdvTNp1LS4AZm7P+Xus9x9UfR30wCsif6fTott+CruntMP4ALCGQ/PA1/Kdj1RTW8hNC83A09EjwsI+/jvB56Lnmdku9ao3jOA/4xeH0v449sO/BwozHJtq4CN0bb8FVA9nbYj8BXgWeBp4CdA4XTYhsAthOMifYQvso+Mtd0Iu0euj/6GniKclZWN+rYT9uMP/s18L2n6L0X1bQPOz9Y2HDV+JzAzW9swnYe62hARkZRyfReTiIiMQQEhIiIpKSBERCQlBYSIiKSkgBARkZQUECLTgJmdYVGPuCLThQJCRERSUkCITICZfdDM/mRmT5jZDRbuh9FuZv/LzB4zs/vNrDaadpWZPZJ0f4LB+ye8zszuM7Mno3mOixZfZsP3rrg5urpaJGsUECJpMrOlwKXAqe6+ChgAPkDoZO8xd18D/Ba4Jprlx8DnPdyf4Kmk4TcD17v76wl9Lw12qbAa+DTh3iTHEvq7EsmavENPIiKRs4A3ABuiH/fFhA7rEsDPomn+D/BLM6sEqtz9t9HwHwE/N7NyoM7dbwdw926AaHl/cveG6P0TwCLgD5n/WCKpKSBE0mfAj9z9CyMGmv33UdON13/NeLuNepJeD6C/T8ky7WISSd/9wCVmNguG7tF8DOHvaLD31b8C/uDuLUCTmZ0WDf8Q8FsP9/VoMLOLo2UURvcJEJl29AtFJE3uvtXM/gG4x8xihF46P0m4EdFyM9tEuCvcpdEslwHfiwLgBeDD0fAPATeY2bXRMt47hR9DJG3qzVXkCJlZu7uXZbsOkcmmXUwiIpKSWhAiIpKSWhAiIpKSAkJERFJSQIiISEoKCBERSUkBISIiKf3/BuEs2HI0n2AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# plotting loss function with epoch\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled MSE: 0.010102761786307174\n",
      "MSE: 4.041104650585807\n",
      "Runtime: 2.5698482990264893 seconds\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "MSE_scaled = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "MSE = mean_squared_error(scaler_y.inverse_transform(y_test), scaler_y.inverse_transform(y_pred)) \n",
    "\n",
    "print(\"Scaled MSE:\",MSE_scaled)\n",
    "print(\"MSE:\",MSE)\n",
    "print(\"Runtime: %s seconds\"%ANN_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>2. Multiple Linear Regression Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from statsmodels.compat import lzip\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "df = pd.read_csv('data/school_grades.csv')\n",
    "\n",
    "#making copy to work with\n",
    "df_copy = df.copy()\n",
    "\n",
    "X = df_copy.drop(['G3'], axis=1)\n",
    "y = df_copy[\"G3\"]\n",
    "\n",
    "#splitting training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                     G3   R-squared:                       0.814\n",
      "Model:                            OLS   Adj. R-squared:                  0.811\n",
      "Method:                 Least Squares   F-statistic:                     296.9\n",
      "Date:                Fri, 28 Feb 2020   Prob (F-statistic):           1.01e-97\n",
      "Time:                        09:42:54   Log-Likelihood:                -582.12\n",
      "No. Observations:                 276   AIC:                             1174.\n",
      "Df Residuals:                     271   BIC:                             1192.\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     -0.2026      1.746     -0.116      0.908      -3.641       3.236\n",
      "age           -0.1274      0.099     -1.293      0.197      -0.321       0.067\n",
      "absences       0.0479      0.016      2.945      0.004       0.016       0.080\n",
      "G1             0.2153      0.072      2.986      0.003       0.073       0.357\n",
      "G2             0.9408      0.064     14.603      0.000       0.814       1.068\n",
      "==============================================================================\n",
      "Omnibus:                      147.175   Durbin-Watson:                   1.793\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              709.878\n",
      "Skew:                          -2.255   Prob(JB):                    7.11e-155\n",
      "Kurtosis:                       9.433   Cond. No.                         341.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Fit regression model\n",
    "start_time = time.time()\n",
    "results = smf.ols('G3 ~ age + absences + G1 + G2', data=pd.concat([X_train,y_train], axis=1)).fit()\n",
    "end_time = time.time()\n",
    "MLR_time = end_time - start_time\n",
    "# Inspect the results\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.741382565073031\n",
      "Runtime: 0.5291106700897217 seconds\n"
     ]
    }
   ],
   "source": [
    "y_pred = results.predict(X_test)\n",
    "\n",
    "MSE = mean_squared_error(y_test, y_pred) \n",
    "\n",
    "print(\"MSE:\",MSE)\n",
    "print(\"Runtime: %s seconds\"%MLR_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
