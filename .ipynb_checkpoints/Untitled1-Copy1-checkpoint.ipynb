{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rahul Kalubowila\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Rahul Kalubowila\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Rahul Kalubowila\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Rahul Kalubowila\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Rahul Kalubowila\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Rahul Kalubowila\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Rahul Kalubowila\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Rahul Kalubowila\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Rahul Kalubowila\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Rahul Kalubowila\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Rahul Kalubowila\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Rahul Kalubowila\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
      "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
     ]
    }
   ],
   "source": [
    "#Variables\n",
    "dataset=np.loadtxt(\"data/TrainData.csv\", delimiter=\",\", skiprows=1)\n",
    "x=dataset[:,0:4]\n",
    "y=dataset[:,3]\n",
    "y=np.reshape(y, (-1,1))\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "print(scaler_x.fit(x))\n",
    "xscale=scaler_x.transform(x)\n",
    "print(scaler_y.fit(y))\n",
    "yscale=scaler_y.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                60        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 173\n",
      "Trainable params: 173\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=4, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 236 samples, validate on 60 samples\n",
      "Epoch 1/150\n",
      "236/236 [==============================] - 0s 843us/sample - loss: 0.2991 - mse: 0.2991 - mae: 0.4991 - val_loss: 0.2920 - val_mse: 0.2920 - val_mae: 0.4939\n",
      "Epoch 2/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.2551 - mse: 0.2551 - mae: 0.4610 - val_loss: 0.2497 - val_mse: 0.2497 - val_mae: 0.4567\n",
      "Epoch 3/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.2160 - mse: 0.2160 - mae: 0.4254 - val_loss: 0.2120 - val_mse: 0.2120 - val_mae: 0.4205\n",
      "Epoch 4/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.1813 - mse: 0.1813 - mae: 0.3897 - val_loss: 0.1788 - val_mse: 0.1788 - val_mae: 0.3856\n",
      "Epoch 5/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.1518 - mse: 0.1518 - mae: 0.3562 - val_loss: 0.1502 - val_mse: 0.1502 - val_mae: 0.3524\n",
      "Epoch 6/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.1262 - mse: 0.1262 - mae: 0.3241 - val_loss: 0.1256 - val_mse: 0.1256 - val_mae: 0.3202\n",
      "Epoch 7/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.1045 - mse: 0.1045 - mae: 0.2924 - val_loss: 0.1042 - val_mse: 0.1042 - val_mae: 0.2892\n",
      "Epoch 8/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0856 - mse: 0.0856 - mae: 0.2617 - val_loss: 0.0860 - val_mse: 0.0860 - val_mae: 0.2611\n",
      "Epoch 9/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0707 - mse: 0.0707 - mae: 0.2337 - val_loss: 0.0706 - val_mse: 0.0706 - val_mae: 0.2351\n",
      "Epoch 10/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0582 - mse: 0.0582 - mae: 0.2059 - val_loss: 0.0583 - val_mse: 0.0583 - val_mae: 0.2115\n",
      "Epoch 11/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0486 - mse: 0.0486 - mae: 0.1832 - val_loss: 0.0489 - val_mse: 0.0489 - val_mae: 0.1900\n",
      "Epoch 12/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0426 - mse: 0.0426 - mae: 0.1657 - val_loss: 0.0419 - val_mse: 0.0419 - val_mae: 0.1719\n",
      "Epoch 13/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0378 - mse: 0.0378 - mae: 0.1513 - val_loss: 0.0373 - val_mse: 0.0373 - val_mae: 0.1581\n",
      "Epoch 14/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0355 - mse: 0.0355 - mae: 0.1422 - val_loss: 0.0343 - val_mse: 0.0343 - val_mae: 0.1479\n",
      "Epoch 15/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0338 - mse: 0.0338 - mae: 0.1364 - val_loss: 0.0325 - val_mse: 0.0325 - val_mae: 0.1412\n",
      "Epoch 16/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0332 - mse: 0.0332 - mae: 0.1333 - val_loss: 0.0314 - val_mse: 0.0314 - val_mae: 0.1366\n",
      "Epoch 17/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0328 - mse: 0.0328 - mae: 0.1314 - val_loss: 0.0307 - val_mse: 0.0307 - val_mae: 0.1335\n",
      "Epoch 18/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0325 - mse: 0.0325 - mae: 0.1302 - val_loss: 0.0302 - val_mse: 0.0302 - val_mae: 0.1317\n",
      "Epoch 19/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0320 - mse: 0.0320 - mae: 0.1289 - val_loss: 0.0299 - val_mse: 0.0299 - val_mae: 0.1311\n",
      "Epoch 20/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0316 - mse: 0.0316 - mae: 0.1278 - val_loss: 0.0295 - val_mse: 0.0295 - val_mae: 0.1304\n",
      "Epoch 21/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0311 - mse: 0.0311 - mae: 0.1266 - val_loss: 0.0292 - val_mse: 0.0292 - val_mae: 0.1299\n",
      "Epoch 22/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0307 - mse: 0.0307 - mae: 0.1257 - val_loss: 0.0289 - val_mse: 0.0289 - val_mae: 0.1297\n",
      "Epoch 23/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0302 - mse: 0.0302 - mae: 0.1245 - val_loss: 0.0286 - val_mse: 0.0286 - val_mae: 0.1290\n",
      "Epoch 24/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0297 - mse: 0.0297 - mae: 0.1232 - val_loss: 0.0282 - val_mse: 0.0282 - val_mae: 0.1279\n",
      "Epoch 25/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0292 - mse: 0.0292 - mae: 0.1220 - val_loss: 0.0278 - val_mse: 0.0278 - val_mae: 0.1270\n",
      "Epoch 26/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0288 - mse: 0.0288 - mae: 0.1210 - val_loss: 0.0275 - val_mse: 0.0275 - val_mae: 0.1262\n",
      "Epoch 27/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0283 - mse: 0.0283 - mae: 0.1198 - val_loss: 0.0271 - val_mse: 0.0271 - val_mae: 0.1252\n",
      "Epoch 28/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0278 - mse: 0.0278 - mae: 0.1185 - val_loss: 0.0267 - val_mse: 0.0267 - val_mae: 0.1241\n",
      "Epoch 29/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0273 - mse: 0.0273 - mae: 0.1172 - val_loss: 0.0262 - val_mse: 0.0262 - val_mae: 0.1228\n",
      "Epoch 30/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0269 - mse: 0.0269 - mae: 0.1158 - val_loss: 0.0258 - val_mse: 0.0258 - val_mae: 0.1214\n",
      "Epoch 31/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0264 - mse: 0.0264 - mae: 0.1145 - val_loss: 0.0253 - val_mse: 0.0253 - val_mae: 0.1201\n",
      "Epoch 32/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0260 - mse: 0.0260 - mae: 0.1131 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1186\n",
      "Epoch 33/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0255 - mse: 0.0255 - mae: 0.1117 - val_loss: 0.0244 - val_mse: 0.0244 - val_mae: 0.1172\n",
      "Epoch 34/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0250 - mse: 0.0250 - mae: 0.1104 - val_loss: 0.0240 - val_mse: 0.0240 - val_mae: 0.1161\n",
      "Epoch 35/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0246 - mse: 0.0246 - mae: 0.1091 - val_loss: 0.0236 - val_mse: 0.0236 - val_mae: 0.1148\n",
      "Epoch 36/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0241 - mse: 0.0241 - mae: 0.1077 - val_loss: 0.0232 - val_mse: 0.0232 - val_mae: 0.1138\n",
      "Epoch 37/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0237 - mse: 0.0237 - mae: 0.1065 - val_loss: 0.0228 - val_mse: 0.0228 - val_mae: 0.1127\n",
      "Epoch 38/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0232 - mse: 0.0232 - mae: 0.1052 - val_loss: 0.0224 - val_mse: 0.0224 - val_mae: 0.1112\n",
      "Epoch 39/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0228 - mse: 0.0228 - mae: 0.1038 - val_loss: 0.0219 - val_mse: 0.0219 - val_mae: 0.1097\n",
      "Epoch 40/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0224 - mse: 0.0224 - mae: 0.1023 - val_loss: 0.0215 - val_mse: 0.0215 - val_mae: 0.1081\n",
      "Epoch 41/150\n",
      "236/236 [==============================] - ETA: 0s - loss: 0.0213 - mse: 0.0213 - mae: 0.099 - 0s 0s/sample - loss: 0.0219 - mse: 0.0219 - mae: 0.1008 - val_loss: 0.0211 - val_mse: 0.0211 - val_mae: 0.1067\n",
      "Epoch 42/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0215 - mse: 0.0215 - mae: 0.0995 - val_loss: 0.0206 - val_mse: 0.0206 - val_mae: 0.1051\n",
      "Epoch 43/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0211 - mse: 0.0211 - mae: 0.0981 - val_loss: 0.0203 - val_mse: 0.0203 - val_mae: 0.1040\n",
      "Epoch 44/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0207 - mse: 0.0207 - mae: 0.0970 - val_loss: 0.0199 - val_mse: 0.0199 - val_mae: 0.1032\n",
      "Epoch 45/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0203 - mse: 0.0203 - mae: 0.0959 - val_loss: 0.0195 - val_mse: 0.0195 - val_mae: 0.1016\n",
      "Epoch 46/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0199 - mse: 0.0199 - mae: 0.0945 - val_loss: 0.0191 - val_mse: 0.0191 - val_mae: 0.1004\n",
      "Epoch 47/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0195 - mse: 0.0195 - mae: 0.0934 - val_loss: 0.0188 - val_mse: 0.0188 - val_mae: 0.0994\n",
      "Epoch 48/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0191 - mse: 0.0191 - mae: 0.0924 - val_loss: 0.0184 - val_mse: 0.0184 - val_mae: 0.0981\n",
      "Epoch 49/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0187 - mse: 0.0187 - mae: 0.0911 - val_loss: 0.0181 - val_mse: 0.0181 - val_mae: 0.0972\n",
      "Epoch 50/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0184 - mse: 0.0184 - mae: 0.0900 - val_loss: 0.0177 - val_mse: 0.0177 - val_mae: 0.0958\n",
      "Epoch 51/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0180 - mse: 0.0180 - mae: 0.0886 - val_loss: 0.0173 - val_mse: 0.0173 - val_mae: 0.0947\n",
      "Epoch 52/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0177 - mse: 0.0177 - mae: 0.0876 - val_loss: 0.0170 - val_mse: 0.0170 - val_mae: 0.0939\n",
      "Epoch 53/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0173 - mse: 0.0173 - mae: 0.0866 - val_loss: 0.0166 - val_mse: 0.0166 - val_mae: 0.0927\n",
      "Epoch 54/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0170 - mse: 0.0170 - mae: 0.0853 - val_loss: 0.0163 - val_mse: 0.0163 - val_mae: 0.0911\n",
      "Epoch 55/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0167 - mse: 0.0167 - mae: 0.0842 - val_loss: 0.0159 - val_mse: 0.0159 - val_mae: 0.0899\n",
      "Epoch 56/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0164 - mse: 0.0164 - mae: 0.0830 - val_loss: 0.0156 - val_mse: 0.0156 - val_mae: 0.0886\n",
      "Epoch 57/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0161 - mse: 0.0161 - mae: 0.0819 - val_loss: 0.0153 - val_mse: 0.0153 - val_mae: 0.0873\n",
      "Epoch 58/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0158 - mse: 0.0158 - mae: 0.0811 - val_loss: 0.0150 - val_mse: 0.0150 - val_mae: 0.0866\n",
      "Epoch 59/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0155 - mse: 0.0155 - mae: 0.0802 - val_loss: 0.0147 - val_mse: 0.0147 - val_mae: 0.0854\n",
      "Epoch 60/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0152 - mse: 0.0152 - mae: 0.0793 - val_loss: 0.0145 - val_mse: 0.0145 - val_mae: 0.0844\n",
      "Epoch 61/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0151 - mse: 0.0151 - mae: 0.0794 - val_loss: 0.0143 - val_mse: 0.0143 - val_mae: 0.0846\n",
      "Epoch 62/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0148 - mse: 0.0148 - mae: 0.0789 - val_loss: 0.0140 - val_mse: 0.0140 - val_mae: 0.0834\n",
      "Epoch 63/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0145 - mse: 0.0145 - mae: 0.0778 - val_loss: 0.0137 - val_mse: 0.0137 - val_mae: 0.0819\n",
      "Epoch 64/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0143 - mse: 0.0143 - mae: 0.0768 - val_loss: 0.0135 - val_mse: 0.0135 - val_mae: 0.0809\n",
      "Epoch 65/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0141 - mse: 0.0141 - mae: 0.0762 - val_loss: 0.0133 - val_mse: 0.0133 - val_mae: 0.0803\n",
      "Epoch 66/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0139 - mse: 0.0139 - mae: 0.0758 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0797\n",
      "Epoch 67/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0137 - mse: 0.0137 - mae: 0.0754 - val_loss: 0.0129 - val_mse: 0.0129 - val_mae: 0.0792\n",
      "Epoch 68/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0135 - mse: 0.0135 - mae: 0.0751 - val_loss: 0.0127 - val_mse: 0.0127 - val_mae: 0.0786\n",
      "Epoch 69/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0133 - mse: 0.0133 - mae: 0.0748 - val_loss: 0.0125 - val_mse: 0.0125 - val_mae: 0.0782\n",
      "Epoch 70/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0132 - mse: 0.0132 - mae: 0.0747 - val_loss: 0.0124 - val_mse: 0.0124 - val_mae: 0.0777\n",
      "Epoch 71/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0130 - mse: 0.0130 - mae: 0.0741 - val_loss: 0.0121 - val_mse: 0.0121 - val_mae: 0.0765\n",
      "Epoch 72/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0129 - mse: 0.0129 - mae: 0.0735 - val_loss: 0.0120 - val_mse: 0.0120 - val_mae: 0.0757\n",
      "Epoch 73/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0127 - mse: 0.0127 - mae: 0.0732 - val_loss: 0.0118 - val_mse: 0.0118 - val_mae: 0.0755\n",
      "Epoch 74/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0126 - mse: 0.0126 - mae: 0.0731 - val_loss: 0.0117 - val_mse: 0.0117 - val_mae: 0.0746\n",
      "Epoch 75/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0125 - mse: 0.0125 - mae: 0.0728 - val_loss: 0.0115 - val_mse: 0.0115 - val_mae: 0.0741\n",
      "Epoch 76/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0124 - mse: 0.0124 - mae: 0.0725 - val_loss: 0.0114 - val_mse: 0.0114 - val_mae: 0.0734\n",
      "Epoch 77/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0122 - mse: 0.0122 - mae: 0.0722 - val_loss: 0.0113 - val_mse: 0.0113 - val_mae: 0.0728\n",
      "Epoch 78/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0122 - mse: 0.0122 - mae: 0.0723 - val_loss: 0.0112 - val_mse: 0.0112 - val_mae: 0.0729\n",
      "Epoch 79/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0120 - mse: 0.0120 - mae: 0.0721 - val_loss: 0.0110 - val_mse: 0.0110 - val_mae: 0.0719\n",
      "Epoch 80/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0120 - mse: 0.0120 - mae: 0.0718 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0716\n",
      "Epoch 81/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0119 - mse: 0.0119 - mae: 0.0717 - val_loss: 0.0109 - val_mse: 0.0109 - val_mae: 0.0713\n",
      "Epoch 82/150\n",
      "236/236 [==============================] - 0s 94us/sample - loss: 0.0118 - mse: 0.0118 - mae: 0.0717 - val_loss: 0.0108 - val_mse: 0.0108 - val_mae: 0.0709\n",
      "Epoch 83/150\n",
      "236/236 [==============================] - 0s 34us/sample - loss: 0.0117 - mse: 0.0117 - mae: 0.0715 - val_loss: 0.0107 - val_mse: 0.0107 - val_mae: 0.0705\n",
      "Epoch 84/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0116 - mse: 0.0116 - mae: 0.0715 - val_loss: 0.0106 - val_mse: 0.0106 - val_mae: 0.0704\n",
      "Epoch 85/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0116 - mse: 0.0116 - mae: 0.0716 - val_loss: 0.0105 - val_mse: 0.0105 - val_mae: 0.0706\n",
      "Epoch 86/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0115 - mse: 0.0115 - mae: 0.0715 - val_loss: 0.0104 - val_mse: 0.0104 - val_mae: 0.0699\n",
      "Epoch 87/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0114 - mse: 0.0114 - mae: 0.0712 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0688\n",
      "Epoch 88/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0113 - mse: 0.0113 - mae: 0.0709 - val_loss: 0.0103 - val_mse: 0.0103 - val_mae: 0.0689\n",
      "Epoch 89/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0113 - mse: 0.0113 - mae: 0.0710 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0691\n",
      "Epoch 90/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0112 - mse: 0.0112 - mae: 0.0711 - val_loss: 0.0102 - val_mse: 0.0102 - val_mae: 0.0690\n",
      "Epoch 91/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0112 - mse: 0.0112 - mae: 0.0709 - val_loss: 0.0101 - val_mse: 0.0101 - val_mae: 0.0684\n",
      "Epoch 92/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0111 - mse: 0.0111 - mae: 0.0707 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0682\n",
      "Epoch 93/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0111 - mse: 0.0111 - mae: 0.0705 - val_loss: 0.0100 - val_mse: 0.0100 - val_mae: 0.0676\n",
      "Epoch 94/150\n",
      "236/236 [==============================] - 0s 38us/sample - loss: 0.0110 - mse: 0.0110 - mae: 0.0703 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0678\n",
      "Epoch 95/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0110 - mse: 0.0110 - mae: 0.0705 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0682\n",
      "Epoch 96/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0109 - mse: 0.0109 - mae: 0.0704 - val_loss: 0.0099 - val_mse: 0.0099 - val_mae: 0.0678\n",
      "Epoch 97/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0109 - mse: 0.0109 - mae: 0.0702 - val_loss: 0.0098 - val_mse: 0.0098 - val_mae: 0.0672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0108 - mse: 0.0108 - mae: 0.0699 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0671\n",
      "Epoch 99/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0108 - mse: 0.0108 - mae: 0.0699 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0674\n",
      "Epoch 100/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0108 - mse: 0.0108 - mae: 0.0699 - val_loss: 0.0097 - val_mse: 0.0097 - val_mae: 0.0671\n",
      "Epoch 101/150\n",
      "236/236 [==============================] - 0s 70us/sample - loss: 0.0107 - mse: 0.0107 - mae: 0.0697 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0666\n",
      "Epoch 102/150\n",
      "236/236 [==============================] - 0s 34us/sample - loss: 0.0107 - mse: 0.0107 - mae: 0.0695 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0666\n",
      "Epoch 103/150\n",
      "236/236 [==============================] - 0s 42us/sample - loss: 0.0107 - mse: 0.0107 - mae: 0.0696 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0671\n",
      "Epoch 104/150\n",
      "236/236 [==============================] - 0s 9us/sample - loss: 0.0106 - mse: 0.0106 - mae: 0.0695 - val_loss: 0.0096 - val_mse: 0.0096 - val_mae: 0.0668\n",
      "Epoch 105/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0106 - mse: 0.0106 - mae: 0.0694 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0668\n",
      "Epoch 106/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0106 - mse: 0.0106 - mae: 0.0692 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0668\n",
      "Epoch 107/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0105 - mse: 0.0105 - mae: 0.0692 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0669\n",
      "Epoch 108/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0105 - mse: 0.0105 - mae: 0.0694 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0673\n",
      "Epoch 109/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0105 - mse: 0.0105 - mae: 0.0697 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0676\n",
      "Epoch 110/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0104 - mse: 0.0104 - mae: 0.0695 - val_loss: 0.0095 - val_mse: 0.0095 - val_mae: 0.0670\n",
      "Epoch 111/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0104 - mse: 0.0104 - mae: 0.0691 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0656\n",
      "Epoch 112/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0104 - mse: 0.0104 - mae: 0.0686 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0661\n",
      "Epoch 113/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0104 - mse: 0.0104 - mae: 0.0689 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0667\n",
      "Epoch 114/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0103 - mse: 0.0103 - mae: 0.0689 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0667\n",
      "Epoch 115/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0103 - mse: 0.0103 - mae: 0.0688 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0666\n",
      "Epoch 116/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0103 - mse: 0.0103 - mae: 0.0686 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0662\n",
      "Epoch 117/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0102 - mse: 0.0102 - mae: 0.0686 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0666\n",
      "Epoch 118/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0102 - mse: 0.0102 - mae: 0.0685 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0663\n",
      "Epoch 119/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0102 - mse: 0.0102 - mae: 0.0685 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0669\n",
      "Epoch 120/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0102 - mse: 0.0102 - mae: 0.0687 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0668\n",
      "Epoch 121/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0102 - mse: 0.0102 - mae: 0.0685 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0664\n",
      "Epoch 122/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0101 - mse: 0.0101 - mae: 0.0685 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0667\n",
      "Epoch 123/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0101 - mse: 0.0101 - mae: 0.0686 - val_loss: 0.0093 - val_mse: 0.0093 - val_mae: 0.0669\n",
      "Epoch 124/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0101 - mse: 0.0101 - mae: 0.0686 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0665\n",
      "Epoch 125/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0101 - mse: 0.0101 - mae: 0.0685 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0667\n",
      "Epoch 126/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0100 - mse: 0.0100 - mae: 0.0685 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0665\n",
      "Epoch 127/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0100 - mse: 0.0100 - mae: 0.0683 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0663\n",
      "Epoch 128/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0100 - mse: 0.0100 - mae: 0.0682 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0663\n",
      "Epoch 129/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0100 - mse: 0.0100 - mae: 0.0682 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0666\n",
      "Epoch 130/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0100 - mse: 0.0100 - mae: 0.0682 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0668\n",
      "Epoch 131/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0099 - mse: 0.0099 - mae: 0.0683 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0669\n",
      "Epoch 132/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0099 - mse: 0.0099 - mae: 0.0682 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0667\n",
      "Epoch 133/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0099 - mse: 0.0099 - mae: 0.0681 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0662\n",
      "Epoch 134/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0099 - mse: 0.0099 - mae: 0.0679 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0666\n",
      "Epoch 135/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0099 - mse: 0.0099 - mae: 0.0683 - val_loss: 0.0092 - val_mse: 0.0092 - val_mae: 0.0670\n",
      "Epoch 136/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0099 - mse: 0.0099 - mae: 0.0682 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0665\n",
      "Epoch 137/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0098 - mse: 0.0098 - mae: 0.0677 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0662\n",
      "Epoch 138/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0098 - mse: 0.0098 - mae: 0.0676 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0664\n",
      "Epoch 139/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0098 - mse: 0.0098 - mae: 0.0676 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0664\n",
      "Epoch 140/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0098 - mse: 0.0098 - mae: 0.0678 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0668\n",
      "Epoch 141/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0098 - mse: 0.0098 - mae: 0.0681 - val_loss: 0.0091 - val_mse: 0.0091 - val_mae: 0.0669\n",
      "Epoch 142/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0097 - mse: 0.0097 - mae: 0.0678 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0661\n",
      "Epoch 143/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0097 - mse: 0.0097 - mae: 0.0673 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0656\n",
      "Epoch 144/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0097 - mse: 0.0097 - mae: 0.0671 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0655\n",
      "Epoch 145/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0097 - mse: 0.0097 - mae: 0.0671 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0661\n",
      "Epoch 146/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0097 - mse: 0.0097 - mae: 0.0673 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0662\n",
      "Epoch 147/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0096 - mse: 0.0096 - mae: 0.0673 - val_loss: 0.0090 - val_mse: 0.0090 - val_mae: 0.0662\n",
      "Epoch 148/150\n",
      "236/236 [==============================] - 0s 0s/sample - loss: 0.0096 - mse: 0.0096 - mae: 0.0671 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0656\n",
      "Epoch 149/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0096 - mse: 0.0096 - mae: 0.0668 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0657\n",
      "Epoch 150/150\n",
      "236/236 [==============================] - 0s 66us/sample - loss: 0.0096 - mse: 0.0096 - mae: 0.0669 - val_loss: 0.0089 - val_mse: 0.0089 - val_mae: 0.0660\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(history.history.keys())\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
